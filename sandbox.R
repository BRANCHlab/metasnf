devtools::load_all()
set.seed(44)
library(sloop)
library(testthat)

dl <- data_list(
    list(subc_v, "scv", "neuroimaging", "continuous"),
    list(cort_t, "cort_t", "neuroimaging", "continuous"),
    list(cort_sa, "cort_sa", "neuroimaging", "continuous"),
    list(income, "income", "neuroimaging", "continuous"),
    uid = "unique_id"
)

config <- snf_config(dl, n_solutions = 3)

my_sdf <- config$"settings_df"

solutions_matrix <- batch_snf(dl, config$"settings_df", verbose = TRUE)

get_cluster_solutions(solutions_matrix)

solutions_matrix3 <- batch_snf2(dl, config, processes = 2)

progressr::with_progress(
    solutions_matrix4 <- batch_snf2(dl, config, processes = 1)
)

progressr::with_progress(
    solutions_matrix2 <- batch_snf2(dl, config)
)

solutions_matrix2

debug(batch_snf2)

unformatted_results <- lapply(
    1:3,
    run_snf,
    dl = dl,
    sc = config,
    keep_sim_mats = FALSE,
    sim_mats_dir = NULL,
    p = NULL
)





df |> head()

solutions_matrix

get_cluster_solutions(solutions_matrix) |> head()

get_cluster_solutions(solutions_matrix2)

identical(solutions_matrix, data.frame(solutions_matrix2))


#' Run variations of SNF.
#'
#' This is the core function of the metasnf package. Using the information
#' stored in a settings_df (see ?settings_df) and a data list
#' (see ?data_list), run repeated complete SNF pipelines to generate
#' a broad space of post-SNF cluster solutions.
#'
#' @param dl A nested list of input data from `data_list()`.
#' @param sdf A data.frame where each row completely defines an SNF
#'  pipeline transforming individual input dataframes into a final cluster
#'  solution. See ?settings_df or
#'  https://branchlab.github.io/metasnf/articles/settings_df.html for more
#'  details.
#' @param processes Specify number of processes used to complete SNF iterations
#'  * `1` (default) Sequential processing: function will iterate through the
#'    `settings_df` one row at a time with a for loop. This option will
#'     not make use of multiple CPU cores, but will show a progress bar.
#'  * `2` or higher: Parallel processing will use the
#'    `future.apply::future_apply` to distribute the SNF iterations across
#'    the specified number of CPU cores. If higher than the number of
#'    available cores, a warning will be raised and the maximum number of
#'    cores will be used.
#'  * `max`: All available cores will be used.
#' @param keep_sim_mats If TRUE, function will return a list where
#'  the first element is the solutions matrix and the second element is a list
#'  of similarity matrices for each row in the solutions_matrix. Default FALSE.
#' @param sim_mats_dir If specified, this directory will be used to
#'  save all generated similarity matrices.
#' @param verbose If TRUE, output progress to console.
#' @return By default, returns a solutions matrix (class "data.frame"), a 
#'  a data frame containing one row for every row of the provided settings
#'  matrix, all the original columns of that settings matrix, and new columns
#'  containing the assigned cluster of each observation from the cluster
#'  solution derived by that row's settings. If `keep_sim_mats` is
#'  TRUE, the function will instead return a list containing the
#'  solutions matrix as well as a list of the final similarity matrices (class
#'  "matrix") generated by SNF for each row of the settings matrix. If 
#'  `suppress_clustering` is TRUE, the solutions matrix will not be returned
#'  in the output.
#' @export
batch_snf2 <- function(dl,
                       sc,
                       processes = 1,
                       keep_sim_mats = FALSE,
                       sim_mats_dir = NULL) {
    if (!inherits(sc, "snf_config")) {
        metasnf_error("`sc` must be a `snf_config` class object.")
    }
    sdf <- sc$"settings_df"
    wm <- sc$"weights_matrix"
    dfl <- sc$"dist_fns_list"
    cfl <- sc$"clust_fns_list"
    #--------------------------------------------------------------------------
    # Check k
    max_k <- max(sdf$"k")
    n_observations <- attributes(dl)$"n_observations"
    if (max_k >= n_observations) {
        metasnf_error(
            "Maximum k ({max_k}) cannot exceed number of ({n_observations})."
        )
    }
    #--------------------------------------------------------------------------
    # Check weights
    if (nrow(wm) != nrow(sdf)) {
        metasnf_error(
            "weights_matrix and settings_df should have equal numbers of rows."
        )
    }
    #--------------------------------------------------------------------------
    # Check clustering functions
    if (max(sdf$"clust_alg") > length(cfl)) {
        metasnf_error(
            "Largest clustering algorithm specified in settings data frame (",
            max(sdf$"clust_alg"), ") exceeds length of clustering functions",
            " list (", length(cfl), ")."
        )
    }
    ###########################################################################
    ## 7. Call separate function for parallel processing
    #if (processes != 1) {
    #    available_cores <- max(future::availableCores())
    #    # Use all available cores
    #    if (processes == "max") {
    #        solutions_matrix <- parallel_batch_snf2(
    #            dl = dl,
    #            dfl = dfl,
    #            cfl = cfl,
    #            sdf = sdf,
    #            wm = wm,
    #            sim_mats_dir = similarity_matrix_dir,
    #            keep_sim_mats = keep_sim_mats,
    #            processes = available_cores
    #        )
    #        solutions_matrix <- as_settings_df(solutions_matrix)
    #        return(solutions_matrix)
    #    } else if (is.numeric(processes)) {
    #        # Use the user-specified number of cores
    #        if (processes > available_cores) {
    #            metasnf_warning(
    #                "You specified ", processes, " processes, but only ",
    #                available_cores, " cores are available. Defaulting to ",
    #                available_cores, " processes."
    #            )
    #            processes <- available_cores
    #        }
    #        solutions_matrix <- parallel_batch_snf2(
    #            dl = dl,
    #            dfl = dfl,
    #            cfl = cfl,
    #            sdf = sdf,
    #            wm = wm,
    #            sim_mats_dir = similarity_matrix_dir,
    #            keep_sim_mats = keep_sim_mats,
    #            processes = processes
    #        )
    #        solutions_matrix <- as_settings_df(solutions_matrix)
    #        return(solutions_matrix)
    #    } else {
    #        metasnf_error("Invalid number of processes specified.")
    #    }
    #}
    ###########################################################################
    # 8. Single thread - Create solutions_matrix
    sol_df <- matrix(
        nrow = nrow(sdf),
        ncol = 2 + attributes(dl)$"n_observations"
    ) |>
        data.frame()
    ###########################################################################
    # 9. Creation of list to store similarity matrices (if requested)
    similarity_matrices <- list()
    ###########################################################################
    # Run SNF
    p <- progressr::progressor(steps = nrow(sdf))
    if (processes > 1) {
        future::plan(future::multisession, workers = processes) 
        apply_fn <- future.apply::future_lapply
    } else {
        apply_fn <- lapply
    }
    unformatted_results <- apply_fn(
        seq_len(nrow(sdf)),
        run_snf,
        dl = dl,
        sc = sc,
        keep_sim_mats = keep_sim_mats,
        sim_mats_dir = sim_mats_dir,
        p = p
    )
    if (processes > 1) {
        future::plan(future::sequential)
    }
    solutions_df <- data.frame(t(sapply(unformatted_results, function(x) x[[1]])))
    sim_mats_list <- lapply(unformatted_results, function(x) x[[2]])
    return(list(solutions_df, sim_mats_list))
}

run_snf <- function(i, dl, sc, keep_sim_mats, sim_mats_dir, p) {
    sdf_row <- sc[["settings_df"]][i, ]
    fused_network <- snf_step(
        dl = drop_inputs(sdf_row, dl),
        scheme = sdf_row$"snf_scheme",
        k = sdf_row$"k",
        alpha = sdf_row$"alpha",
        t = sdf_row$"t",
        cnt_dist_fn = sc$"dist_fns_list"$"cnt_dist_fns"[[sdf_row$"cnt_dist"]],
        dsc_dist_fn = sc$"dist_fns_list"$"dsc_dist_fns"[[sdf_row$"dsc_dist"]],
        ord_dist_fn = sc$"dist_fns_list"$"ord_dist_fns"[[sdf_row$"ord_dist"]],
        cat_dist_fn = sc$"dist_fns_list"$"cat_dist_fns"[[sdf_row$"cat_dist"]],
        mix_dist_fn = sc$"dist_fns_list"$"mix_dist_fns"[[sdf_row$"mix_dist"]],
        weights_row = sc$"weights_matrix"[i, , drop = FALSE]
    )
    solution <- sc$"clust_fns_list"[[sdf_row$"clust_alg"]](fused_network)
    if (!is.null(sim_mats_dir)) {
        utils::write.csv(
            x = fused_network,
            file = similarity_matrix_path(sim_mats_dir, i),
            row.names = TRUE
        )
    }
    if (!keep_sim_mats) {
        fused_network <- NULL
    }
    if (!is.null(p)) {
        p()
    }
    return(list("solution" = solution, "fused_network" = fused_network))
}

