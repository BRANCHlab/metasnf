---
title: "An example metasnf pipeline"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{An example metasnf pipeline}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

**What is this package?**

*metasnf* is a package that facilitates usage of the meta clustering paradigm described in [Caruana et al., 2006](https://doi.org/10.1109/ICDM.2006.103) with the similarity network fusion (SNF) data integration procedure developed in [Wang et al., 2014](https://doi.org/10.1038/nmeth.2810).

This package enables repeated iterations of SNF with distinct clustering hyperparameters and combinations of input variables by making use of a few key data structures.

<br>

**Why use meta clustering?**

Clustering algorithms strive to give you a solution that is optimal in terms of some metric of clustering compactness.
Perhaps in some cases with huge amounts of data and a simple set of features to consider, like examining the preferred genres of Netflix customers, the most compact solution will immediately produce something useful (distinct tastes that can quickly be used to inform advertising).

When clustering noisy biological data over a wide range of data domains, however, you're probably not going to get a crisp and "correct" answer that shines above all other clustering solutions.
Depending on how things are preprocessed, how things are weighted, what features are included, what hyperparameters are used, you may end up with all sorts of qualitatively different solutions that tell you different interesting things about the starting dataset.

What are the chances that the best clustering solution for your use case is also the one with the best [silhouette score](https://en.wikipedia.org/wiki/Silhouette_(clustering)) or other [evaluation metric](https://en.wikipedia.org/wiki/Cluster_analysis#Evaluation_and_assessment)?

To address this issue, the meta clustering procedure [Caruana et al., 2006](https://doi.org/10.1109/ICDM.2006.103) generates a large number of reasonable clustering solutions, clusters those solutions into qualitatively similar ones, and lets the user examine those "meta clusters" to find something that seems like it'll be the most useful.

In this vignette, we work through a slightly different approach also mentioned in the original meta clustering paper, which involved using our own clustering usefulness rule to enable automatic solution from the pool of large cluster solutions (without needing to cluster the cluster solutions themselves or do any manual inspections).
We also go through some functions that will help you go through the authentic clustering-of-clusters based approach if that is what you prefer.


## 0. Examining the (fake) data

```{r setup}
library(metasnf)
```

The metansf package comes with a few mock dataframes based on real data from the Adolescent Brain Cognitive Development study:

- `abcd_anxiety` (anxiety scores from the CBCL)
- `abcd_depress` (depression scores from the CBCL)
- `abcd_cort_t` (cortical thicknesses)
- `abcd_cort_sa` (cortical surface areas in mm^2)
- `abcd_subc_v` (subcortical volumes in mm^3)
- `abcd_income` (household income on a 1-3 scale)
- `abcd_pubertal` (pubertal status on a 1-5 scale)

Here's what the cortical thickness data looks like:

```{r}
dim(abcd_cort_t)

str(abcd_cort_t[1:5, 1:5])

abcd_cort_t[1:5, 1:5]
```

The first column `subjectkey` is the unique identifier (UID) for all subjects in the ABCD study.
This will also be the required UID for your data, but don't worry about that just yet.


Here's the household income data:

```{r}
dim(abcd_income)

str(abcd_income[1:5, ])

abcd_income[1:5, ]
```

Putting everything in a list will help us get quicker summaries of all the data.

```{r}
abcd_data <- list(
    abcd_anxiety,
    abcd_depress,
    abcd_cort_t,
    abcd_cort_sa,
    abcd_subc_v,
    abcd_income,
    abcd_pubertal
)

# The number of rows in each dataframe:
lapply(abcd_data, dim)

# Whether or not each dataframe has missing values:
lapply(abcd_data,
    function(x) {
        any(is.na(x))
    }
)
```

Some of our data has missing values and not all of our dataframes have the same number of participants.


## 1. Generating the `data_list`

The `data_list` structure is basically just a list of dataframes (like the one already created), but with some additional features to facilitate repeated clustering.
It should only contain the input dataframes we want to directly use as inputs for the clustering.
I'll set aside the anxiety and depression dataframes for now and just use the other dataframes as clustering inputs.

```{r}
data_list <- generate_data_list(
    list(abcd_cort_t, "cortical_thickness", "neuroimaging", "numeric"),
    list(abcd_cort_sa, "cortical_surface_area", "neuroimaging", "numeric"),
    list(abcd_subc_v, "subcortical_volume", "neuroimaging", "numeric"),
    list(abcd_income, "household_income", "demographics", "numeric"),
    list(abcd_pubertal, "pubertal_status", "demographics", "numeric"),
    old_uid = "subjectkey"
)
```

Building the `data_list` is the most laborious part of the process.
The first entries are all lists which contains the following elements:

1. The actual dataframe
2. A name for the dataframe (string)
3. A name for the *domain* of the dataframe (string)
4. The type of variable stored in the dataframe (options are numeric, categorical, and mixed)

Finally, there's an argument for the `old_uid` (the column name that currently uniquely identifies all the subjects in your data).

Behind the scenes, this function is building a nested list that keeps track of all this information, but it is also:

- Converting the UID of the data into "subjectkey"
- Removing all observations that contain any NAs
- Removing all subjects who are not present in all input dataframes
- Arranging the subjects in all the dataframe by their UID

Any rows containing NAs are removed.
If you don't want a bunch of your data to get slashed because there are a few NAs sprinkled around here and there, consider using [imputation](https://en.wikipedia.org/wiki/Imputation_(statistics)).
The `mice` package in R is nice for this.

We can get a summary of our constructed `data_list` with the `summarize_dl` function:

! Change sdl and all its calls to summarize_dl

```{r}
#summarize_dl(data_list)
```

## Generating the `design_matrix`

The design matrix stores all the information about the settings we'd like to use for each of our SNF runs.
Here is an empty one that we can use to just look at the columns:

! Ensure any function responsible for building an object begins with generate

```{r}
#generate_design_matrix(data_list)
```

The columns are:
- inc* - binary columns indicating whether or not an input dataframe is included (1) or excluded (0) from the corresponding SNF run
- K - the nearest neighbors hyperparameter used for SNF (an input to the function SNFtool::SNF)
- alpha - Referred to as eta in the manuscript and alpha in the SNFtool code, this is a hyperparameter for affinity matrix generation
- snf_scheme - the specific way in which input data gets collapsed into a final fused network:

One important consideration of SNF is choosing how to organize features into dataframes. In the original SNF paper, reference was made to data of the same measurement type.
If a set of features are all measurements of the same 

`generate_design_matrix` uses `data_list` as a parameter

The purpose of adjusting these settings is to give us access to a broader space of reasonable SNF solutions.
The broader the space, the better of an approximation our top chosen solution will be to the top possible solution.
This is by no means the objectively best (irony not intended) set of settings to 



## References

Caruana, Rich, Mohamed Elhawary, Nam Nguyen, and Casey Smith. 2006. “Meta Clustering.” In Sixth International Conference on Data Mining (ICDM’06), 107–18. https://doi.org/10.1109/ICDM.2006.103.

Wang, Bo, Aziz M. Mezlini, Feyyaz Demir, Marc Fiume, Zhuowen Tu, Michael Brudno, Benjamin Haibe-Kains, and Anna Goldenberg. 2014. “Similarity Network Fusion for Aggregating Data Types on a Genomic Scale.” Nature Methods 11 (3): 333–37. https://doi.org/10.1038/nmeth.2810.
